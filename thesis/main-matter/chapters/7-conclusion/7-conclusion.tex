%===========================================================================
%	VII. Conclusion
%===========================================================================

This final chapter retrospects on the work and findings inside this bachelor's thesis. It started out with background information on DataOps and testing methodologies. It conducted an actual state analysis of a preexisting, static \ac{mba} data analytics solution based on the state-of-the-art findings. This determined action items for the DataOps enablement and testing enhancement of the solution. The thesis then proposed a general DataOps testing framework and applied its steps on the Conversion Stage of the data pipeline in theory. Then, the DataOps process and testing framework have been practically implemented. Finally, the new solution was evaluated by means of the key goals of this thesis, being the understanding of DataOps testing, similarities and differences to DevOps testing, as well as limitation of the solution.

\section{Key Findings}
During research, design, implementation, and evaluation, the following key characteristics were found:

As with traditional software solution testing, data analytics testing supports the quality of new version releases. It provides confidence in the product for all stakeholders, leading to less post-deployment issues, and therefore, to less cost, time, and risk during production-grade usage. Eventually, well-tested data analytics solutions are expected to provide more valuable business insights for the organizations that take advantage of them.

Moreover, DataOps testing is an inherent part of DataOps that benefits from technical support through automation and the separation of execution environments. Nevertheless, DataOps remains an agile work model that requires an adequate agile mindset. The DataOps \ac{cicd} pipeline can only recognize test failures with actually available tests. If a developer team decides to neglect testing and work around potential testing mechanisms, there will be no tests that could fail, resulting in a passing deployment. From a qualitative point of view, this is unacceptable but could not be realistically enforced with additional technical measures. Instead, testing conventions and best practices should be known and accepted by the performing developers. Then, DataOps testing can be very valuable for correct and confident solution development and deployment.

Even with the required agile mindset, test quality might be an issue. Since these tests are written by human developers, they might not take certain edge cases into account, leading to an insufficiently tested solution. Again, test quality measurements could be implemented into the solution but should also be supported by non-automated processes, like peer code reviews, etc.

The testing design process should consider that historic analyses might need to be re-conducted, aiming for consistent results regardless of the current version of the data analytics solution. Therefore, regression testing and the conditional execution of features need to be taken into account.

While DataOps testing can be achieved by utilizing traditional software testing tools, it does not follow the exact same process of DevOps testing. Since data analytics solutions often depend on a variety of external services, these also need to be considered during testing. This goes against the traditional testing pyramid that aims for isolated, granular unit tests. Instead, DataOps tests should not strictly stick to the traditional testing levels but provide semantically categorized testing suites that reflect the desired workflow of the solution.

\section{Proposal for Further Research}
The preliminary goal of the thesis' project was to demonstrate the discipline of DataOps testing by means of an exemplarily chosen data analytics scenario. Throughout the research and development process, it became clear that different types of data analytics projects are expected to have different types of requirements. It might be reasonable to evaluate the testing design framework and process inside other use cases, using different technologies. For instance, it is expected that more complex, \acs{ml}-driven data analytics will require additional infrastructure and testing methodologies. In general, the solution at hand covers deterministic testing. It might be of great interest to find out how such testing is conducted with predictive data analytics. \newpage

Picking up on the test quality issue finding from this thesis, implementation and evaluation of test quality assurance measures might concretize if testing conventions can be reasonably supported by automated mechanisms. \\\

In conclusion, the demonstration of \ac{mba} DataOps testing underlined the importance and capability of data analytics development and testing automation. With further research and development based on this work, generally applicable DataOps testing frameworks and tools for a variety of use cases and complexities could be created, resulting in better data analytics solutions and outcomes for organizations throughout several industries.