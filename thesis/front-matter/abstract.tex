\begin{abstract}
The development and operation of data analytics solutions have faced significant challenges. With rapidly changing requirements and the urge for innovation, data analytics projects require a modern approach for their creation and maintenance. Reality shows that many of these projects are still conducted in a static, non-iterative nature, leading to slow operationalization and a general loss of trust in their value.

\textit{DataOps} is a new paradigm for supporting the emergence of data analytics solutions through automation processes and an agile work model. Learnings from DevOps in software development are adopted and transferred to building data analytics solutions. One of these significant learnings is the discipline of testing. As with traditional software development, data analytics testing verifies the integrity and correct behavior of a solution, resulting in more confidence and trust in the product.

In order to evaluate DataOps testing, a preexisting data analytics pipeline for conducting Market Basket Analyses is leveraged and enhanced by DataOps methodologies. Then, a general DataOps testing framework is proposed that covers the duality of software and data quality testing. This includes data event handling inside the solution and its validation through pathological test data suites and automated test cases. The framework is practically applied on the solution such that all tests are performed before releasing new versions of the solution. Focussing on analytics feature development, the new solution is evaluated by means of its general testing workflow, its similarities and differences to DevOps testing, as well as potential technical limitations.

The evaluation verifies the validity of the testing framework inside the given use case. The automatic execution of all testing suites prior to deployment recognizes potential issues, resulting in a more productive and efficient development iteration process. As with DevOps, it requires an agile mindset as well as an accurate testing design. This design is expected to match the actual workflow of the data analytics solution, leading to less testing isolation when compared to DevOps testing.

Finally, the thesis encourages to validate the proposed testing framework inside different use cases of varying complexity degrees. Furthermore, it is to find out if additional technical measures could increase the quality of the automatic testing process.
\end{abstract}
\selectlanguage{ngerman}
\singlespacing
\begin{abstract}
	Die Entwicklung und der Einsatz von Data Analytics Lösungen wurde vor viele Herausforderungen gestellt. Durch rasante Anforderungsänderungen und den Drang nach Innovation benötigen Data Analytics Projekte einen modernen Ansatz für ihre Entstehung und Wartung. In der Realität werden diese Projekte oft mit statischen, nicht-iterativen Arbeitsweisen durchgeführt. Dies führt zu einer schwergängigen Inbetriebnahme sowie zu einem allgemeinen Verlust in das Vertrauen des Wertes dieser Lösungen.

\textit{DataOps} beschreibt eine neue Methode, welche den Enstehungsprozess von Data Analytics Lösungen durch Automatisierung und ein agiles Arbeitsmodell unterstützt. Erfahrungen aus DevOps werden übernommen und auf Data Analytics Lösungen angepasst. Eine dieser Erfahrungen ist das Testing. Wie auch in der traditionellen Softwareentwicklung bestätigt Testing die Integrität sowie die korrekte Arbeitsweise der Lösung, was langfristig zu mehr Sicherheit und Vertrauen in das Projekt führt.

Um DataOps Testing zu evaluieren wird zunächst eine bereits bestehende Data Analytics Pipeline betrachtet, welche für die Erstellung von Warenkorbanalysen verwendet wird. Diese wird um DataOps-Technologien und -Methodiken erweitert. Daraufhin wird ein allgemeines Testing Framework vorgeschlagen, welches die Dualität des Testings von Software- und Datenaspekten berücksichtigt. Dieses beinhaltet das Data Event Handling der Lösung sowie die automatisierte Validierung der Funktionsweise über zugeschnittene Testdatensätze. Das Framework wird auf die DataOps-Lösung angewendet, sodass sämtliche Tests vor der Veröffentlichung einer neuen Lösungsversion durchgeführt und evaluiert werden. Mit einem Fokus auf die Entwicklung auf neue Funktionalität in der Data Analytics Lösung wird diese letztendlich evaluiert. Dies geschieht im Hinblick auf die praktische Funktionsweise des Testing-Prozesses, auf die Gemeinsamkeiten und Unterschiede zum DevOps-Testing, sowie auf mögliche technische Einschränkungen.

Die Evaluation unterstreicht die korrekte Funktionsweise des Frameworks innerhalb des Fallbeispiels. Das automatisierte Testing stellt mögliche Probleme und Fehlfunktionen unmittelbar vor Bereitstellung einer neuen Version fest, was letztendlich zu einem effizienteren und produktiveren Entwicklungsprozess führt. Wie auch mit Dev-Ops ist DataOps ein agiler Prozess, welcher ein agile sowie testfokussierte Denkweise voraussetzt. Das Testing Design sollte hier die eigentliche Funktionsweise der Lösung reflektieren und weniger Wert auf Isolation und Trennbarkeit legen.

Abschließend wird vorgeschlagen, das vorgestellte Testing Framework auf andere Data Science Projekte anzuwenden, um auch dort seine Funktionsweise zu bestätigen. Weiterhin könnte es sinnvoll sein, weitere automatische Mechanismen zu evaluieren, welche die Qualität des Testings kontrollieren und verstärken könnten.
\end{abstract}
\onehalfspacing
\selectlanguage{english}