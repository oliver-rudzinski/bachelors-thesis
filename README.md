# Setup and Implementation of an Automated Testing Pipeline for a DataOps Use Case

The development and operation of data analytics solutions have faced significant challenges. With rapidly changing requirements and the urge for innovation, data analytics projects require a modern approach for their creation and maintenance. Reality shows that many of these projects are still conducted in a static, non-iterative nature, leading to slow operationalization and a general loss of trust in their value.

*DataOps* is a new paradigm for supporting the emergence of data analytics solutions through automation processes and an agile work model. Learnings from DevOps in software development are adopted and transferred to building data analytics solutions. One of these significant learnings is the discipline of testing. As with traditional software development, data analytics testing verifies the integrity and correct behavior of a solution, resulting in more confidence and trust in the product.

In order to evaluate DataOps testing, a preexisting data analytics pipeline for conducting Market Basket Analyses is leveraged and enhanced by DataOps methodologies. Then, a general DataOps testing framework is proposed that covers the duality of software and data quality testing. This includes data event handling inside the solution and its validation through pathological test data suites and automated test cases. The framework is practically applied on the solution such that all tests are performed before releasing new versions of the solution. Focussing on analytics feature development, the new solution is evaluated by means of its general testing workflow, its similarities and differences to DevOps testing, as well as potential technical limitations.

The evaluation verifies the validity of the testing framework inside the given use case. The automatic execution of all testing suites prior to deployment recognizes potential issues, resulting in a more productive and efficient development iteration process. As with DevOps, it requires an agile mindset as well as an accurate testing design. This design is expected to match the actual workflow of the data analytics solution, leading to less testing isolation when compared to DevOps testing.

Finally, the thesis encourages to validate the proposed testing framework inside different use cases of varying complexity degrees. Furthermore, it is to find out if additional technical measures could increase the quality of the automatic testing process.
